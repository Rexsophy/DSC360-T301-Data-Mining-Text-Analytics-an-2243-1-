{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf4852ba-8001-4edb-9cb7-468e621da260",
   "metadata": {},
   "source": [
    "#### Week 10 Exercise 10.2 Author: Rex Gayas Course & Section: DSC360-T301 Data Mining: Text Analytics an (2243-1) Date: 18 FEB 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a3004-317b-4cf4-b83e-4f4bb54429c8",
   "metadata": {},
   "source": [
    "#### Loading the Dataset. Checking and Preliminary Comprehension of Stucture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f8fd3df-5923-4307-98b2-ccd02869f219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10326</td>\n",
       "      <td>The room was kind of clean but had a VERY stro...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10327</td>\n",
       "      <td>I stayed at the Crown Plaza April -- - April -...</td>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10328</td>\n",
       "      <td>I booked this hotel through Hotwire at the low...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10329</td>\n",
       "      <td>Stayed here with husband and sons on the way t...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10330</td>\n",
       "      <td>My girlfriends and I stayed here to celebrate ...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id10326  The room was kind of clean but had a VERY stro...   \n",
       "1  id10327  I stayed at the Crown Plaza April -- - April -...   \n",
       "2  id10328  I booked this hotel through Hotwire at the low...   \n",
       "3  id10329  Stayed here with husband and sons on the way t...   \n",
       "4  id10330  My girlfriends and I stayed here to celebrate ...   \n",
       "\n",
       "        Browser_Used Device_Used Is_Response  \n",
       "0               Edge      Mobile   not happy  \n",
       "1  Internet Explorer      Mobile   not happy  \n",
       "2            Mozilla      Tablet   not happy  \n",
       "3   InternetExplorer     Desktop       happy  \n",
       "4               Edge      Tablet   not happy  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File path of Hotel Reviews dataset\n",
    "file_path = 'D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Mining\\\\Week 10\\\\archive\\\\hotel-reviews.csv'\n",
    "hotel_reviews = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to confirm structure of dataset\n",
    "hotel_reviews.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b33d0c0-d04f-4025-bd5f-248982debf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User_ID', 'Description', 'Browser_Used', 'Device_Used', 'Is_Response'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the column names of the DataFrame\n",
    "hotel_reviews.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b2677-7577-4c4a-9f98-13a17ba69b1b",
   "metadata": {},
   "source": [
    "#### Preprocess the Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2742d5-65bc-467b-b0f6-512872cfe5da",
   "metadata": {},
   "source": [
    "This step cleans the text data to improve the performance of the sentiment analysis model. We remove HTML tags, accented characters, convert text to lowercase, remove extra newlines, special characters, digits, extra whitespace, and stopwords. These steps standardize the text and reduce noise in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28b7a597-08db-4cf6-8743-924306b3d4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Cleaned_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The room was kind of clean but had a VERY stro...</td>\n",
       "      <td>room was kind clean but had very strong smell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I stayed at the Crown Plaza April -- - April -...</td>\n",
       "      <td>i stayed crown plaza april april staff was fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I booked this hotel through Hotwire at the low...</td>\n",
       "      <td>i booked this hotel through hotwire lowest pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stayed here with husband and sons on the way t...</td>\n",
       "      <td>stayed here with husband sons way alaska cruis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My girlfriends and I stayed here to celebrate ...</td>\n",
       "      <td>my girlfriends i stayed here celebrate our th ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0  The room was kind of clean but had a VERY stro...   \n",
       "1  I stayed at the Crown Plaza April -- - April -...   \n",
       "2  I booked this hotel through Hotwire at the low...   \n",
       "3  Stayed here with husband and sons on the way t...   \n",
       "4  My girlfriends and I stayed here to celebrate ...   \n",
       "\n",
       "                                 Cleaned_Description  \n",
       "0  room was kind clean but had very strong smell ...  \n",
       "1  i stayed crown plaza april april staff was fri...  \n",
       "2  i booked this hotel through hotwire lowest pri...  \n",
       "3  stayed here with husband sons way alaska cruis...  \n",
       "4  my girlfriends i stayed here celebrate our th ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define the TextNormalizer class used from Week 4\n",
    "class TextNormalizer:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(['a', 'an', 'the', 'and', 'or', 'for', 'to', 'of', 'in', 'on', 'at', 'by', 'up', 'out', 'as'])\n",
    "\n",
    "    def strip_html_tags(self, text):\n",
    "        pattern = re.compile('<.*?>')\n",
    "        return re.sub(pattern, '', text)\n",
    "\n",
    "    def remove_accented_chars(self, text):\n",
    "        return text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "    def text_to_lower(self, text):\n",
    "        return text.lower()\n",
    "\n",
    "    def remove_extra_newlines(self, text):\n",
    "        return re.sub(r'\\r\\n|\\r|\\n', ' ', text)\n",
    "\n",
    "    def remove_special_characters_and_digits(self, text, remove_digits=True):\n",
    "        pattern = r'[^a-zA-Z\\s]' if not remove_digits else r'[^a-zA-Z0-9\\s]'\n",
    "        return re.sub(pattern, '', text)\n",
    "\n",
    "    def remove_extra_whitespace(self, text):\n",
    "        return re.sub(' +', ' ', text.strip())\n",
    "\n",
    "    def remove_stopwords(self, text):\n",
    "        return ' '.join([word for word in text.split() if word not in self.stop_words])\n",
    "\n",
    "    def normalize_corpus(self, corpus):\n",
    "        normalized_corpus = []\n",
    "        for doc in corpus:\n",
    "            doc = self.strip_html_tags(doc)\n",
    "            doc = self.remove_accented_chars(doc)\n",
    "            doc = self.text_to_lower(doc)\n",
    "            doc = self.remove_extra_newlines(doc)\n",
    "            doc = self.remove_special_characters_and_digits(doc)\n",
    "            doc = self.remove_extra_whitespace(doc)\n",
    "            doc = self.remove_stopwords(doc)\n",
    "            normalized_corpus.append(doc)\n",
    "        return normalized_corpus\n",
    "\n",
    "# Instantiate the text normalizer\n",
    "text_normalizer = TextNormalizer()\n",
    "\n",
    "# Normalize the review text\n",
    "hotel_reviews['Cleaned_Description'] = text_normalizer.normalize_corpus(hotel_reviews['Description'])\n",
    "\n",
    "# Display the first few rows of the cleaned text\n",
    "hotel_reviews[['Description', 'Cleaned_Description']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae51f1f-b24e-43a3-8c19-99bd563c1ae6",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb01d61-61a3-4373-b60a-812c687ae192",
   "metadata": {},
   "source": [
    "This process of converts categorical text data into a numerical format as subsequent models require input to be numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b06e9a9f-460b-4ddf-ba19-7b751c3fecb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Response</th>\n",
       "      <th>Is_Response_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not happy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not happy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not happy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not happy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Is_Response  Is_Response_Encoded\n",
       "0   not happy                    1\n",
       "1   not happy                    1\n",
       "2   not happy                    1\n",
       "3       happy                    0\n",
       "4   not happy                    1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode 'Is_Response' column: 'happy' as 0 and 'not happy' as 1\n",
    "hotel_reviews['Is_Response_Encoded'] = hotel_reviews['Is_Response'].apply(lambda x: 0 if x == 'happy' else 1)\n",
    "\n",
    "# Display the first few rows to check the encoded column\n",
    "hotel_reviews[['Is_Response', 'Is_Response_Encoded']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c6eb1-c124-4f98-8ed9-3a30eefe4ca5",
   "metadata": {},
   "source": [
    "#### Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775a849-a39a-47c7-895d-464714b28f72",
   "metadata": {},
   "source": [
    "To evaluate the performance of the sentiment analysis model, we need to split our dataset into training, validation, and testing sets. This allows us to train our model on one subset of the data and test its performance on another, unseen subset, providing an estimate of performance on an independent dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7740cc06-56f8-40de-aae9-23bcc8c3d07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 23358 samples\n",
      "Validation set: 7787 samples\n",
      "Test set: 7787 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Save 20% of the data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    hotel_reviews['Cleaned_Description'],  # the features used for training a.k.a the cleaned reviews\n",
    "    hotel_reviews['Is_Response_Encoded'],  # the target variable or the label encoded 'Is_Response'\n",
    "    test_size=0.2,  # specifies the proportion of the dataset to include in the test split\n",
    "    random_state=42  # a seed for the random number generator for reproducible results\n",
    ")\n",
    "\n",
    "# Then split the training data into a training set and a validation set\n",
    "# Taking 25% of the original training set to create the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,  # the remaining features for training\n",
    "    y_train,  # the remaining target variable for training\n",
    "    test_size=0.25,  # specifies the proportion of the training dataset to include in the validation split\n",
    "    random_state=42  # a seed for the random number generator for reproducible results\n",
    ")\n",
    "\n",
    "# It should be noted that X_train and y_train are for training, X_val and y_val are for validation, \n",
    "# and X_test and y_test are for final testing.\n",
    "\n",
    "# Confirming the size of each dataset\n",
    "print(f'Training set: {X_train.shape[0]} samples')\n",
    "print(f'Validation set: {X_val.shape[0]} samples')\n",
    "print(f'Test set: {X_test.shape[0]} samples')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c6352-25ed-40d8-9c66-dc26285c1496",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis with AFINN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1092b2cc-7381-4b41-ad88-2b2e8ecde941",
   "metadata": {},
   "source": [
    "From the text, the AFINN lexicon is a list of English words rated for valence with an integer between minus five (negative) and plus five (positive). The words have been manually labeled by Finn Årup Nielsen between 2009 and 2011. We will use the AFINN lexicon to score the sentiment of the hotel reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e071627c-ccbd-4bf7-a524-f0a843adc90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "# Initialize Afinn sentiment analyzer\n",
    "afinn = Afinn()\n",
    "\n",
    "# Define a function to apply Afinn and calculate sentiment scores\n",
    "def calculate_sentiment_scores(reviews):\n",
    "    sentiment_scores = [afinn.score(review) for review in reviews]\n",
    "    return sentiment_scores\n",
    "\n",
    "# Calculate sentiment scores for each dataset\n",
    "train_sentiments = calculate_sentiment_scores(X_train)\n",
    "val_sentiments = calculate_sentiment_scores(X_val)\n",
    "test_sentiments = calculate_sentiment_scores(X_test)\n",
    "\n",
    "# Convert sentiment scores to binary labels based on the sentiment score being positive (>0) or negative (<=0)\n",
    "y_train_pred = [1 if score > 0 else 0 for score in train_sentiments]\n",
    "y_val_pred = [1 if score > 0 else 0 for score in val_sentiments]\n",
    "y_test_pred = [1 if score > 0 else 0 for score in test_sentiments]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cc03a9c-cb20-40dd-901a-204a64821ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentiment scores and their corresponding binary labels from the training set:\n",
      "Review: i stayed here with my dog during one snow storms hotel did excellant job keeping sidewalk clear they were middle renovating lobby which had fireplace several nice seating areas there were computers tv with seating area it was nice they let my lb dog stay there but gave me doggy bag that looked like it had been used previously i cleaned after my dog outside but there were no trash cans anywhere outside hotel me dispose his poop electronic lock my door didnt work i stopped front desk let them know hours later no one had come fix it which meant if i left my room it would not be locked i called front desk again they arrived mins later fix it seems it just needed new battery cleanliness side my room was clean room did not have refridgerator microwave but there was shared microwave near vending machines it was dirty with something spilled all over inside it days also room that held vending machines microwave was dark isolated beds were comforatable i liked that sink was bathroom not part room itself there was chair large flat screen tvand computer room with free internet access it was little slow but nice have room room also had free wifi large desk area this hotel is within walking distance upenn which is why i choose it if you skip having your room cleaned you receive credit which can be used site restaurant i would stay here again but price i expect better service cleaner cooking areas, Sentiment score: 15.0, Binary label: 1\n",
      "Review: reviews palomar are overstated this is average hotel every respect checkin desk hotel personnel are very efficient wine tasting is friendly rooms are clean comfortable but well used hallways were not cleaned days same debrise was left carpets while i tried use bankmachine insect tried use it well palomar is good location transit many interesting restaurants washington dc but it is overrated over priced, Sentiment score: 13.0, Binary label: 1\n",
      "Review: we stayed nights club quarters downtown when i first booked i was little apprehensive about being location that i thought was so far from action but how wrong i was william wall street location is great there are excellent restaurants coffee shops nearby subway access is easy hotel is clean quiet well situated hotel is right next subway line being financial district there is security staff around hours day we always felt safe hotel reception staff are highly professional they went their way assist us i would certainly stay this hotel again i think that it was better than staying midtown lower west east sides because downtown location is much less touristy, Sentiment score: 8.0, Binary label: 1\n",
      "Review: husband i spent one night w our anniversary upon arrival i was little thrown back fact that bar was right near entrance doors they had dj playing worst music ever house music gag it was really loud after navigating through noise crowd we found front desk girl front desk was amazing she asked if it was special occasion we told her yes she bumped us th floor with amazing view she also gave us vouchers free drinks room was small but confortable very clean bed was perfect so much so i was asleep pm hubby didnt like thatlol one negative is there was no coffee maker room i have have coffee luckily all you have do is call front desk request one we went smoke when we came back we had coffee maker free anniversary dessert waiting us they really made us feel special parking is normal area about park overnight you definitely want call them about mins before youre going down youll have stand there wait room service menu had nothing that i wanted but you are heart sf there is plenty food walking distance i suggest amber indian restaurant it is one best pool is small i believe it only had chairs total pool is almost hrs i believe its closed from am even though its small if you go right it you can have it all yourself overall this place is very nice i would have given stars but i dont give stars anyone would definitely stay again, Sentiment score: 20.0, Binary label: 1\n",
      "Review: we stayed hotel harrington june we have large family so we booked large family room it had twin beds queen beds bathroom we enjoyed our stay it is excellent location we came from airport metro walked almost every monumentmuseum possible we did take metro arlington metro is very reasonable we felt very safe during our stay hotel is old bit run down but clean great location price was right too we dined espn zone which was located right across street from hotel also our childrens favorite place eat was ollies trollies this little hamburger place has great fries old fashion decor kids loved milkshakes all all great hotel great location great trip we would stay here again, Sentiment score: 28.0, Binary label: 1\n"
     ]
    }
   ],
   "source": [
    "# Print out the first 5 sentiment scores and their corresponding binary labels from the training set\n",
    "print(\"Sample sentiment scores and their corresponding binary labels from the training set:\")\n",
    "for review, score, label in zip(X_train[:5], train_sentiments[:5], y_train_pred[:5]):\n",
    "    print(f\"Review: {review}, Sentiment score: {score}, Binary label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a392f78-c56e-4826-ab51-e51da2b83ee0",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a1a4a-5a41-42a1-b592-38955a291211",
   "metadata": {},
   "source": [
    "After scoring the sentiment of the reviews using AFINN, we will evaluate our model's performance by comparing the predicted sentiment scores to the actual labels in the test set. We will use accuracy, precision, recall, and F1-score as our metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5becba82-8bc8-409b-8b9c-6dc40d067cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2312\n",
      "Precision: 0.2456\n",
      "Recall: 0.6723\n",
      "F1 Score: 0.3597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate performance metrics on the test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658deba-0cab-45cf-8086-c8249d91dbc0",
   "metadata": {},
   "source": [
    "#### Observations and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c55d0cd-27a0-4f83-8767-aef3a4d426c1",
   "metadata": {},
   "source": [
    "The high recall and low precision could indicate that the model is over-predicting the “not happy” class. In other words, it is better at catching “not happy” reviews at the cost of incorrectly classifying some “happy” reviews as “not happy”.\n",
    "\r\n",
    "It should be noted that the AFINN lexicon model uses a fixed list of words with assigned sentiment scores. They may not capture the sentiment of words that are not in the lexicon or understand the context in which words are used. For consideration, a context-aware sentiment analysis approach such as machine learning models trained on large, labeled datasets that may better understand the sentiment. Seemingly, this model does not improve over time or adapt to new expressions of sentiment. Hence, training a supervised machine learning model that can learn from a labeled dataset or using a deep learning model (which is in Week 11) may exhibit improvement of its predictions over time.\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
