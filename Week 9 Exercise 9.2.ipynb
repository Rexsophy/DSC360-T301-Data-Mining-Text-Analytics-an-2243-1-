{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf915a95-649d-4f78-9dd7-93effba22b0e",
   "metadata": {},
   "source": [
    "#### Week 9 Milestone 9.3 Author: Rex Gayas Course & Section: DSC360-T301 Data Mining: Text Analytics an (2243-1) Date: 11 FEB 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3071e6f-9ec3-4e05-89e5-35750977e35d",
   "metadata": {},
   "source": [
    "##### 1. Run the following sentence through your tagger: “Fourteen days ago, Emperor Palpatine left San Diego, CA for Tatooine to follow Luke Skywalker.” Report on the tags applied to the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "facf78fa-41e5-4849-9933-5773be3c33e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted NER tags for the test sentence:\n",
      "[['O', 'O', 'O', 'B-per', 'I-per', 'O', 'B-geo', 'I-geo', 'O', 'O', 'B-geo', 'O', 'O', 'B-per', 'I-per']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "# Function to extract features from a sentence\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to transform a sentence into CRF features\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "# Function to extract labels from a sentence\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Mining\\\\Week 9\\\\ner_dataset.csv\", encoding=\"latin1\")\n",
    "df = df.ffill()\n",
    "\n",
    "# Creating a list of sentences\n",
    "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                    s[\"POS\"].values.tolist(),\n",
    "                                                    s[\"Tag\"].values.tolist())]\n",
    "grouped_df = df.groupby(\"Sentence #\").apply(agg_func)\n",
    "sentences = [s for s in grouped_df]\n",
    "\n",
    "# Using a smaller subset for faster training\n",
    "sentences = sentences[:1000]  # Considering only the first 1000 sentences\n",
    "\n",
    "# Extract features and labels\n",
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Train the CRF model\n",
    "crf = CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=30, all_possible_transitions=True)\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on a single sentence\n",
    "test_sentence = [(\"Fourteen\", \"CD\"), (\"days\", \"NNS\"), (\"ago\", \"RB\"), (\"Emperor\", \"NNP\"), \n",
    "                 (\"Palpatine\", \"NNP\"), (\"left\", \"VBD\"), (\"San\", \"NNP\"), (\"Diego\", \"NNP\"), \n",
    "                 (\"CA\", \"NNP\"), (\"for\", \"IN\"), (\"Tatooine\", \"NNP\"), (\"to\", \"TO\"), \n",
    "                 (\"follow\", \"VB\"), (\"Luke\", \"NNP\"), (\"Skywalker\", \"NNP\")]\n",
    "\n",
    "# Extract features from the test sentence\n",
    "test_sentence_features = sent2features(test_sentence)\n",
    "\n",
    "# Predict NER tags for the test sentence\n",
    "test_sentence_tags = crf.predict([test_sentence_features])\n",
    "\n",
    "# Output the results\n",
    "print(\"Predicted NER tags for the test sentence:\")\n",
    "print(test_sentence_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea399ed8-4ef2-47e8-84ca-5452b4a21407",
   "metadata": {},
   "source": [
    "##### Run the same sentence through spaCy’s NER engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fecca95a-eed6-4d09-be1a-057721ad89ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities, Phrase and Label\n",
      "Fourteen days ago 0 17 DATE\n",
      "Palpatine 27 36 PERSON\n",
      "San Diego 42 51 GPE\n",
      "CA 53 55 WORK_OF_ART\n",
      "Tatooine 60 68 PERSON\n",
      "Luke Skywalker 79 93 PERSON\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fourteen days ago\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", Emperor \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Palpatine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " left \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    San Diego\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " for \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tatooine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " to follow \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Luke Skywalker\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the pre-trained spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# The sentence to be processed\n",
    "sentence = \"Fourteen days ago, Emperor Palpatine left San Diego, CA for Tatooine to follow Luke Skywalker.\"\n",
    "\n",
    "# Process the sentence using spaCy\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Print the named entities in the sentence\n",
    "print(\"Named Entities, Phrase and Label\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "# Visualize the named entities in Jupyter Notebook\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f57dc55-4d24-468f-bfde-9af10bc7fa16",
   "metadata": {},
   "source": [
    "##### Compare and contrast the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7133b748-950b-4424-be8c-520bf9535049",
   "metadata": {},
   "source": [
    "The CRF model and spaCy's NER engine exhibit different strengths in entity recognition. The CRF model, trained on a subset of data, identified \"Emperor Palpatine\" and \"Luke Skywalker\" as persons but did not recognize \"Fourteen days ago\" as a date, while spaCy correctly identified the date and persons but misclassified \"CA\" as a work of art. The performance of the CRF model is dependent on the quality and quantity of training data, as well as the feature set used, and in this instance, it appears to be underfitting, likely due to insufficient training iterations and data. On the other hand, spaCy's pre-trained model, which requires no additional training, offers a broader range of entity classifications and demonstrates a more general and accurate entity recognition capability.\n",
    "\r\n",
    "In terms of practicality, the pre-trained spaCy model is more user-friendly and can be deployed quickly for a wide range of applications, making it highly practical for immediate use. Conversely, the CRF model provides flexibility and can potentially achieve higher accuracy for specific tasks with proper training, but this comes at the cost of increased complexity in model tuning and longer setup times. Therefore, for tasks requiring rapid deployment and general use, spaCy's out-of-the-box functionality is advantageous, whereas for specialized tasks that can benefit from customized training, a CRF model might be the better option despite potential for a more process-intensive setback. \r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
