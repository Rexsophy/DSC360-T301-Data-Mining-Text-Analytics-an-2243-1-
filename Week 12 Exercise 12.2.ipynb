{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "752673cd-a75b-4b82-aa5e-8025253bf930",
   "metadata": {},
   "source": [
    "## Week 12 Exercise 12.2 Author: Rex Gayas Course & Section: DSC360-T301 Data Mining: Text Analytics an (2243-1) Date: 02 MAR 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c555a-dcec-451f-b8a7-7f69ee71942b",
   "metadata": {},
   "source": [
    "##### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d009e0b8-79b3-47f7-9de5-6b6f91ba7100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Tweet Id                                          Tweet URL  \\\n",
      "0  \"1167429261210218497\"  https://twitter.com/animalhealthEU/status/1167...   \n",
      "1  \"1167375334670557185\"  https://twitter.com/PennyBrohnUK/status/116737...   \n",
      "2  \"1167237977615097861\"  https://twitter.com/lordbyronaf/status/1167237...   \n",
      "3  \"1167236897078480898\"  https://twitter.com/CountessDavis/status/11672...   \n",
      "4  \"1167228378191204353\"  https://twitter.com/Local12/status/11672283781...   \n",
      "\n",
      "  Tweet Posted Time (UTC)                                      Tweet Content  \\\n",
      "0    30 Aug 2019 13:30:00  Pets change our lives &amp; become a part of o...   \n",
      "1    30 Aug 2019 09:55:43  Another spot of our #morethanmedicine bus in #...   \n",
      "2    30 Aug 2019 00:49:54  What a great team ⁦@HealthSourceOH⁩ ⁦@Local12⁩...   \n",
      "3    30 Aug 2019 00:45:37  What a great team ⁦@HealthSourceOH⁩ ⁦@Local12⁩...   \n",
      "4    30 Aug 2019 00:11:46  What a great team ⁦@HealthSourceOH⁩ ⁦@Local12⁩...   \n",
      "\n",
      "  Tweet Type                Client  Retweets Received  Likes Received  \\\n",
      "0      Tweet  Twitter Ads Composer                  0               4   \n",
      "1      Tweet       Twitter Web App                  0               5   \n",
      "2    ReTweet   Twitter for Android                  0               0   \n",
      "3    ReTweet   Twitter for Android                  0               0   \n",
      "4    ReTweet             TweetDeck                  0               0   \n",
      "\n",
      "   Tweet Location Tweet Language  ...                 Name        Username  \\\n",
      "0        Brussels        English  ...   AnimalhealthEurope  animalhealthEU   \n",
      "1   Pill, Bristol        English  ...       Penny Brohn UK    PennyBrohnUK   \n",
      "2       Ohio, USA        English  ...         Lord ByronAF     lordbyronaf   \n",
      "3             NaN        English  ...  Lisa Countess davis   CountessDavis   \n",
      "4  Cincinnati, OH        English  ...     Local 12/WKRC-TV         Local12   \n",
      "\n",
      "                                            User Bio Verified or Non-Verified  \\\n",
      "0  AnimalhealthEurope represents manufacturers of...             Non-Verified   \n",
      "1  We help people live well with the impact of ca...             Non-Verified   \n",
      "2  It's easier to be who you are, than it is to b...             Non-Verified   \n",
      "3  I am named after @ElvisPresley daughter Lisa M...             Non-Verified   \n",
      "4  Local 12 is #Cincinnati's trusted source for b...                 Verified   \n",
      "\n",
      "                          Profile URL Protected or Non-protected  \\\n",
      "0  https://twitter.com/animalhealthEU              Non-Protected   \n",
      "1    https://twitter.com/PennyBrohnUK              Non-Protected   \n",
      "2     https://twitter.com/lordbyronaf              Non-Protected   \n",
      "3   https://twitter.com/CountessDavis              Non-Protected   \n",
      "4         https://twitter.com/Local12              Non-Protected   \n",
      "\n",
      "  User Followers  User Following  User Account Creation Date Impressions  \n",
      "0           3697             542        17 Dec 2012 09:14:15        7394  \n",
      "1           3227            1571        15 Sep 2010 09:44:02        6454  \n",
      "2           7808            8617        25 Jul 2012 15:43:47           0  \n",
      "3            291              81        26 Jan 2017 18:21:42           0  \n",
      "4         198675             651        02 Sep 2008 20:09:44           0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Mining\\\\Week 5\\\\twitter_sample.csv\"\n",
    "\n",
    "# Load the dataset into a Pandas DataFrame\n",
    "tweets_df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe to verify\n",
    "print(tweets_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef26e3c-d049-48f3-b12d-c2aa37af45f2",
   "metadata": {},
   "source": [
    "##### Preparing the spaCy Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3e669e8-2ebf-44f5-9144-9d33450055ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608c6196-6e50-4eee-9d59-34aa30294991",
   "metadata": {},
   "source": [
    "spaCy’s small English  language model has been loaded which will be used to process and tokenize the tweets. It creates a Doc object, which is a sequence of tokens that spaCy uses for all its language processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71779ed6-d6e0-4b72-bb8c-0f5710eeec8e",
   "metadata": {},
   "source": [
    "##### Defining the Matcher and Patterns for Social Causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c5edfb0-dd82-4c73-8777-c34625e642ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Matcher with the spaCy vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define patterns for social causes\n",
    "social_cause_patterns = [\n",
    "    [{\"LOWER\": \"support\"}, {\"IS_PUNCT\": True, \"OP\": \"?\"}, {\"LOWER\": \"the\"}, {\"LOWER\": \"cause\"}],\n",
    "    [{\"LOWER\": \"raise\"}, {\"LOWER\": \"awareness\"}],\n",
    "    [{\"LOWER\": \"fight\"}, {\"LOWER\": \"against\"}],\n",
    "    [{\"LOWER\": \"advocate\"}, {\"LOWER\": \"for\"}],\n",
    "    [{\"LOWER\": \"social\"}, {\"LOWER\": \"justice\"}],\n",
    "    [{\"LOWER\": \"human\"}, {\"LOWER\": \"rights\"}],\n",
    "    [{\"LOWER\": \"help\"}, {\"LOWER\": \"the\"}, {\"LOWER\": \"poor\"}],\n",
    "    [{\"LOWER\": \"poverty\"}, {\"LOWER\": \"relief\"}],\n",
    "    [{\"LOWER\": \"equality\"}],\n",
    "    [{\"LOWER\": \"environmental\"}, {\"LOWER\": \"protection\"}],\n",
    "    [{\"LOWER\": \"climate\"}, {\"LOWER\": \"change\"}],\n",
    "    [{\"LOWER\": \"political\"}, {\"LOWER\": \"reform\"}],\n",
    "    [{\"LOWER\": \"donate\"}, {\"LOWER\": \"to\"}],\n",
    "    [{\"LOWER\": \"charity\"}],\n",
    "    [{\"LOWER\": \"volunteer\"}, {\"LOWER\": \"for\"}],\n",
    "    [{\"LOWER\": \"fundraiser\"}],\n",
    "    [{\"LOWER\": \"make\"}, {\"LOWER\": \"a\"}, {\"LOWER\": \"difference\"}]\n",
    "]\n",
    "\n",
    "# Add patterns to the matcher\n",
    "matcher.add(\"SOCIAL_CAUSE\", social_cause_patterns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a7a525-fe22-4b2c-9706-81b301d7563b",
   "metadata": {},
   "source": [
    "Defined a set of patterns that are likely to capture references to social causes within tweets. These patterns are based on common phrases and wordings that are associated with social advocacy or mentions of social issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436c972-16c2-4da2-9243-5bae0aaf5960",
   "metadata": {},
   "source": [
    "##### Extracting Social Cause Mentions from the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "44172bc5-35e1-4350-8fd9-5ccf3a383a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matched Text</th>\n",
       "      <th>Identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>NOAH</td>\n",
       "      <td>raise awareness</td>\n",
       "      <td>SOCIAL_CAUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Ibrahima KOUMA</td>\n",
       "      <td>environmental protection</td>\n",
       "      <td>SOCIAL_CAUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>AnimalhealthEurope</td>\n",
       "      <td>environmental protection</td>\n",
       "      <td>SOCIAL_CAUSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name              Matched Text    Identifier\n",
       "125                NOAH           raise awareness  SOCIAL_CAUSE\n",
       "359      Ibrahima KOUMA  environmental protection  SOCIAL_CAUSE\n",
       "380  AnimalhealthEurope  environmental protection  SOCIAL_CAUSE"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to process tweets and extract matches\n",
    "def extract_social_causes(tweet_content):\n",
    "    # Process the tweet content with the spaCy model\n",
    "    doc = nlp(tweet_content)\n",
    "    # Find matches in the doc\n",
    "    matches = matcher(doc, as_spans=True)\n",
    "    # Concatenate all matched text into a single string separated by commas\n",
    "    return ', '.join([span.text.strip() for span in matches if span.text.strip()])\n",
    "\n",
    "# Apply the function to the 'Tweet Content' column to extract matches\n",
    "tweets_df['Matched Text'] = tweets_df['Tweet Content'].apply(extract_social_causes)\n",
    "\n",
    "# Filter out rows with no matches\n",
    "tweets_with_matches = tweets_df[tweets_df['Matched Text'] != '']\n",
    "\n",
    "# Create a new DataFrame with the relevant columns\n",
    "matches_df = tweets_with_matches[['Name', 'Matched Text']].copy()\n",
    "\n",
    "# Add the 'Identifier' column with the constant value 'SOCIAL_CAUSE'\n",
    "matches_df['Identifier'] = 'SOCIAL_CAUSE'\n",
    "\n",
    "# Display the DataFrame with the matched social cause phrases\n",
    "matches_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2715d8b-3fa9-464a-90e1-fb7f49af0e26",
   "metadata": {},
   "source": [
    "Defined a function “extract_social_causes” that takes the tweet content, processes it with the NLP model to create a doc object, and then finds all spans in the doc that match predefined patterns. Included only spans where the text is not just whitespace.\n",
    "Applied this to “Tweet Content” column of DataFrame and created a new column “Matched Text” that contains the matched phrases for each tweet. Filtered out any tweets that didn't match any patterns and created a new “DataFrame matches_df” containing the tweet author's name, the matched text, and a constant identifier denoting that the match is related to a social cause.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
