{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb1b638",
   "metadata": {},
   "source": [
    "#### Week 7 Exercise 7.2 Author: Rex Gayas Course & Section: DSC360-T301 Data Mining: Text Analytics an (2243-1) Date: 28 JAN 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f7f8f8d-cd99-422f-9d76-2815268451c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and text mining\n",
      "Drug repositioning with adaptive graph convolutional\n",
      "networks\n",
      "Xinliang Sun1, Xiao Jia1, Zhangli Lu1, Jing Tang2, Min Li1,*\n",
      "1School of Computer Science and Engineering, Central South University, Changsha, Hunan 410083, China\n",
      "2Research Program in Systems Oncology, Faculty of Medicine, University of Helsinki, FI00014 Helsinki, Finland\n",
      "*Corresponding author. School of Computer Science and Engineering, Central South University, Changsha, 932 South Lushan Road, Hunan 410083, China\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Attempt to read from PDF File\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# File path of the PDF Research Article\n",
    "file_path = \"D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Mining\\\\Week 7\\\\btad748.pdf\"\n",
    "\n",
    "# Extract text\n",
    "full_text = extract_text_from_pdf(file_path)\n",
    "\n",
    "# Print the first 500 characters to verify\n",
    "print(full_text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "146e9479-cd12-4bc4-b590-e8aa9a9e7893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and text mining\n",
      "Drug repositioning with adaptive graph convolutional\n",
      "networks\n",
      "Xinliang Sun1, Xiao Jia1, Zhangli Lu1, Jing Tang2, Min Li1,*\n",
      "1School of Computer Science and Engineering, Central South University, Changsha, Hunan 410083, China\n",
      "2Research Program in Systems Oncology, Faculty of Medicine, University of Helsinki, FI00014 Helsinki, Finland\n",
      "*Corresponding author.\n",
      "School of Computer Science and Engineering, Central South University, Changsha, 932 South Lushan Road, Hunan 410083, China .\n",
      "\n",
      "E-mail: limin@mail.csu.edu.cn\n",
      "Associate Editor: Macha Nikolski\n",
      "Abstract\n",
      "Motivation:\n",
      "Drug repositioning is an effective strategy to identify new indications for existing drugs, providing the quickest possible transition\n",
      "from bench to bedside.\n",
      "With the rapid development of deep learning, graph convolutional networks (GCNs) have been widely adopted for drugrepositioning tasks.\n",
      "However, prior GCNs based methods exist limitations in deeply integrating node features and topological structures, which\n",
      "may hinder the capability of GCNs.\n",
      "\n",
      "Results:\n",
      "In this study, we propose an adaptive GCNs approach, termed AdaDR, for drug repositioning by deeply integrating node features and to-\n",
      "pological structures.\n",
      "Distinct from conventional graph convolution networks, AdaDR models interactive information between them with adaptivegraph convolution operation, which enhances the expression of model.\n",
      "Concretely, AdaDR simultaneously extracts embeddings from node fea-\n",
      "tures and topological structures and then uses the attention mechanism to learn adaptive importance weights of the embeddings.\n",
      "Experimental\n",
      "results show that AdaDR achieves better performance than multiple baselines for drug repositioning.\n",
      "Moreover, in the case study, exploratoryanalyses are offered for ﬁnding novel drug–disease associations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Preprocess the text with spaCy\n",
    "doc = nlp(full_text)\n",
    "\n",
    "# Print out the first 10 sentences to verify spaCy's parsing of the text\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    print(sent.text)\n",
    "    if i > 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43a757cb-ae5d-4fee-bac4-d37ffa1689a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\n', 671), ('drug', 146), ('disease', 99), ('al', 71), ('et', 64), ('adadr', 62), ('graph', 60), ('feature', 44), ('model', 41), ('drugs', 40)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Calculate word frequencies, excluding stop words and punctuation\n",
    "words = [token.text.lower() for token in doc if not token.is_punct and not token.is_stop]\n",
    "word_frequencies = Counter(words)\n",
    "\n",
    "# Print the most common words\n",
    "print(word_frequencies.most_common(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68c90bc2-062a-4780-b65c-124e102705d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Normalize the frequencies\n",
    "max_frequency = max(word_frequencies.values())\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word] / max_frequency\n",
    "\n",
    "# Score each sentence by summing the normalized frequencies of each word in the sentence\n",
    "sentence_scores = {}\n",
    "for sent in doc.sents:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies:\n",
    "            if sent not in sentence_scores:\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "\n",
    "# Verify the type of sentence_scores is a dictionary\n",
    "print(type(sentence_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "068f6067-5947-4052-babb-c7fe8a7bba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      " With the drug kNN graph Gr¼ðAr;XrÞand the disease\n",
      "kNN graph Gd¼ðAd;XdÞin feature space, we utilize thetypical GCN ( Kipf and Welling 2017 ) to represent con-\n",
      "structed graphs’ lth layer output:\n",
      "ZðlÞ\n",
      "r¼ReLU D/C01\n",
      "2rArD/C012\n",
      "rZðl/C01Þ\n",
      "rWðlÞ\n",
      "r/C16/C17\n",
      "ZðlÞ\n",
      "d¼ReLU D/C01\n",
      "2\n",
      "dAdD/C012\n",
      "dZðl/C01Þ\n",
      "dWðlÞ\n",
      "d/C16/C178\n",
      ">><\n",
      ">>:(3)\n",
      "where ZðlÞ\n",
      "r;ZðlÞ\n",
      "d2Rnare the kth layer’s information propa-\n",
      "gated for drugs and diseases, respectively; WðlÞ\n",
      "r;WðlÞ\n",
      "dare the\n",
      "weight matrices of the lth layer in GCN. Similarly, ai\n",
      "Tr¼softmax ðxi\n",
      "TrÞandaj\n",
      "Td¼softmax ðxj\n",
      "TdÞ.F o r\n",
      "all the ndrug nodes and mdisease nodes, we obtain the learned\n",
      "weights afr¼½ai\n",
      "Fr/C138;atr¼½ai\n",
      "Tr/C1382Rn/C21and afd¼½aj\n",
      "Fd/C138;atd¼\n",
      "½aj\n",
      "Td/C1382Rm/C21, and denote aFr¼diagðafrÞ;aTr¼diagðatrÞand\n",
      "aFd¼diagðafdÞ;aTd¼diagðatdÞ. Then we combine these\n",
      "embeddings to obtain the final drug embedding Zrand disease\n",
      "embedding Zd:\n",
      "Zr¼aFr/C1ZFrþaTr/C1ZTr\n",
      "Zd¼aFd/C1ZFdþaTd/C1ZTd(10)\n",
      "2.5 Prediction and optimization\n",
      "To obtain the final prediction result, we concatenate two\n",
      "obtained embeddings to represent the drug–disease pair.\n",
      " Method Gdataset Cdataset LRSSL Ldataset\n",
      "AUROC\n",
      "AdaDR-w/o-l 0.949 60.005 0.964 60.005 0.951 60.009 0.881 60.004\n",
      "AdaDR-w/o-a 0.949 60.010 0.964 60.004 0.945 60.010 0.879 60.003\n",
      "AdaDR-w/o-f 0.943 60.006 0.958 60.006 0.937 60.012 0.878 60.003\n",
      "AdaDR-w/o-t 0.908 60.008 0.936 60.012 0.899 60.013 0.805 60.010\n",
      "AdaDR 0.952 60.006 0.966 60.006 0.950 60.010 0.881 60.003\n",
      "AUPRC\n",
      "AdaDR-w/o-l 0.576 60.048 0.659 60.025 0.470 60.044 0.568 60.009\n",
      "AdaDR-w/o-a 0.569 60.045 0.657 60.032 0.454 60.036 0.564 60.008\n",
      "AdaDR-w/o-f 0.564 60.043 0.632 60.033 0.445 60.042 0.563 60.010\n",
      "AdaDR-w/o-t 0.324 60.045 0.439 60.043 0.294 60.041 0.398 60.004\n",
      "AdaDR 0.588 60.041 0.671 60.030 0.475 60.042 0.569 60.0098 Sun et al.potential drugs for breast carcinoma and AD and adopt\n",
      "highly reliable sources (i.e. CTD and PubMed) to check the\n",
      "predicted drug–disease associations. Then, the two normalized matrix can be utilized to capturethe similarity of ndrug nodes in different spaces as S\n",
      "r\n",
      "FandSr\n",
      "T\n",
      "as follows:\n",
      "Sr\n",
      "F¼ZFr/C1ZT\n",
      "Fr\n",
      "Sr\n",
      "T¼ZTr/C1ZT\n",
      "Tr(13)\n",
      " We then nor-\n",
      "malize the attention values with softmax function to get the ﬁ-\n",
      "nal drug weight and disease weight:\n",
      "ai\n",
      "Fr¼softmax ðxi\n",
      "FrÞ¼expðxi\n",
      "FrÞ\n",
      "expðxi\n",
      "FrÞþexpðxi\n",
      "TrÞ\n",
      " The entry Ad\n",
      "ijof matrix Adis deﬁned as:\n",
      "Ad\n",
      "ij¼1;ifdj2~NkðdiÞ\n",
      "0;otherwise(\n",
      "(2)\n",
      "where~NkðdiÞ¼f dig[N kðdiÞis a set of di’s extended k-near-\n",
      "est neighbors including ri, and NkðdiÞis the k-nearest neigh-\n",
      "bors of drug di.\n",
      " After one shared attention vector\n",
      "q2Rh0/C21is used to get the attention value xi\n",
      "Fras follows:\n",
      "xi\n",
      "Fr¼qT/C1tanh/C16\n",
      "WFr/C1ðzi\n",
      "FrÞTþbFr/C17\n",
      "(8)\n",
      "where WFr2Rh0/C2his the weight matrix and bFr2Rh0/C21is the\n",
      "bias vector for embedding matrix ZFr. Besides, the consist ency\n",
      "constraint is used to push closer the embeddings in different spaces in this module; (iii) prediction module to concatenate embeddings as the output t o\n",
      "predict results.2 Sun et al.2.1 Datasets\n",
      "To comprehensively evaluate the proposed model performance,\n",
      "we exploit four benchmark datasets, e.g. Gdataset ( Gottlieb\n",
      "et al. 2011 ), Cdataset ( Luo et al. 2016 ), Ldataset ( Yuet al.\n",
      "2021 ), and LRSSL ( Liang et al. 2017 ), which are widely used in\n",
      "drug repositioning tasks. The entry Ar\n",
      "ijofAris defined as:\n",
      "Ar\n",
      "ij¼1;ifrj2~NkðriÞ\n",
      "0;otherwise(\n",
      "(1)\n",
      "where~NkðriÞ¼f rig[N kðriÞis a set of ri’s extended k-near-\n",
      "est neighbors including ri, and NkðriÞis the k-nearest neigh-\n",
      "bors of drug ri. Considering the prediction resultcan be correlated with them, we use the attention mechanism\n",
      "to adaptively learn the corresponding importance of drug\n",
      "embeddings and disease embeddings as follows:\n",
      "ða\n",
      "fr;atrÞ¼attðZFr;ZTrÞ\n",
      "ðafd;atdÞ¼attðZFd;ZTdÞ(7)\n",
      "here att is a neural network which performs the attention op-\n",
      "eration. After\n",
      "the message passing step, we can accumulate incoming mes-\n",
      "sages at every node by summing over all neighbors\n",
      "Nt2f0;1gðriÞconnected by a speciﬁc edge-type, and by accumu-\n",
      "lating the results for each edge type into a single vector\n",
      "representation:\n",
      "hi¼rsumX\n",
      "j2N t2f0;1gðriÞMPðlj!i;tÞ ! aj\n",
      "Fd¼softmax ðxj\n",
      "FdÞ¼expðxj\n",
      "FdÞ\n",
      "expðxj\n",
      "FdÞþexpðxj\n",
      "TdÞ(9)\n",
      " The AUROC and AUPRC are obtain under the 10 times 10-fold cross-validation on Gdataset, Cdataset, LRSSL, and Ldataset.a\n",
      "Dataset MBiRW iDrug BNNR DRHGCN NIMCGCN DRWBNCF AdaDR\n",
      "AUROC\n",
      "Gdataset 0.896 60.014 0.905 60.019 0.937 60.010 0.948 60.011 0.821 60.011 0.923 60.013 0.95260.006\n",
      "Cdataset 0.920 60.008 0.926 60.010 0.952 60.010 0.964 60.005 0.827 60.017 0.941 60.011 0.96660.006\n",
      "LRSSL 0.893 60.015 0.900 60.008 0.922 60.012 0.96160.006 0.777 60.012 0.935 60.011 0.950 60.010\n",
      "Ldataset 0.765 60.007 0.838 Data and text mining\n",
      "Drug repositioning with adaptive graph convolutional\n",
      "networks\n",
      "Xinliang Sun1, Xiao Jia1, Zhangli Lu1, Jing Tang2, Min Li1,*\n",
      "1School of Computer Science and Engineering, Central South University, Changsha, Hunan 410083, China\n",
      "2Research Program in Systems Oncology, Faculty of Medicine, University of Helsinki, FI00014 Helsinki, Finland\n",
      "*Corresponding author. In our model, we assign a specific transformation for\n",
      "each edge type, resulting in edge-type specific messages lj!i;t,\n",
      "from diseases( d)jto drugs( r)iof the following form:\n",
      "MPðlj!i;tÞ¼1\n",
      "cijWtxj (4)\n",
      "where cijis a symmetric normalization constantﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ\n",
      "jN ðriÞjjN ð djÞjp\n",
      ", with NðriÞdenoting the set of neighbors of\n",
      "drug node iandNðdjÞdenoting the set of neighbors of disease\n",
      "node j.Wtis an edge-type speciﬁc parameter matrix and xjis\n",
      "the feature vector of disease node j. Messages MPðli!j;tÞfrom\n",
      "drugs to diseases are processed in an analogous way. Besides, for biological processes that have not been ex-plored in depth, e.g. serotonin receptor( Geldenhuys and Van\n",
      "der Schyf 2011 ) and urotransmitter reuptake( Francis 2005 ),\n",
      "may provide new perspectives for the treatment of AD.\n",
      "4 Conclusion\n",
      "In this paper, we have proposed AdaDR based on graph neuralnetworks and attention mechanism to model the drug–disease\n",
      "Figure 7. Dataset No. of drugs No. of diseases No. of associations Sparsity\n",
      "Gdataset 593 313 1933 0.0104\n",
      "Cdataset 663 409 2532 0.0093\n",
      "LRSSL 763 681 3051 0.0059\n",
      "Ldataset 269 598 18 416 0.1145Adaptive graph convolutional networks 3nodes is the same as that of disease nodes, because the model\n",
      "is trained without side information of the nodes. •MBiRW ( Luoet al. 2016 ) is a bi-random walk algorithm,\n",
      "which uses sparse drug–disease associations to enhance\n",
      "the similarity measures of drug and disease to perform as-sociation prediction.•iDrug ( Chen et al. 2020 ) is a matrix completion based\n",
      "method, which utilizes the cross-network drug-related in-formation to achieve better model performance.\n",
      " The binary cross-entropy (BCE) loss is used as the main\n",
      "loss:\n",
      "Lbce¼/C0X\n",
      "ði;jÞyij/C1logð^yijÞþð1/C0yijÞ/C1logð1/C0^yijÞ (12)\n",
      "here ( i,j) denotes the pair for drug iand disease j;yijis the\n",
      "truth label.\n"
     ]
    }
   ],
   "source": [
    "# Select the top scoring sentences for the summary\n",
    "number_of_sentences = int(len(sentence_scores) * 0.05)\n",
    "\n",
    "# Use nlargest to obtain the top scoring sentences\n",
    "summary_sentences = nlargest(number_of_sentences, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "# Combine the top sentences into a summary\n",
    "summary_text = ' '.join([sent.text for sent in summary_sentences])\n",
    "print(\"Summary:\\n\", summary_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b5eccdd-3077-4646-b16d-32aeb097f6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of 'The Black Cat':\n",
      " One morning, in cool blood, I slipped a noose about its neck and hung it to the limb of a tree;—hung it with the tears streaming from my eyes, and with the bitterest remorse at my heart;—hung it because I knew that it had loved me, and because I felt it had given me no reason of offence;—hung it because I knew that in so doing I was committing a sin—a deadly sin that would so jeopardize my immortal soul as to place it—if such a thing wore possible—even beyond the reach of the infinite mercy of the Most Merciful and Most Terrible God.      No sooner had the reverberation of my blows sunk into silence, than I was answered by a voice from within the tomb!—by a cry, at first muffled and broken, like the sobbing of a child, and then quickly swelling into one long, loud, and continuous scream, utterly anomalous and inhuman—a howl—a wailing shriek, half of horror and half of triumph, such as might have arisen only out of hell, conjointly from the throats of the dammed in their agony and of the demons that exult in the damnation.      These walls—are you going, gentlemen?—these walls are solidly put together;” and here, through the mere phrenzy of bravado, I rapped heavily, with a cane which I held in my hand, upon that very portion of the brick-work behind which stood the corpse of the wife of my bosom.      It did not make its appearance during the night—and thus for one night at least, since its introduction into the house, I soundly and tranquilly slept; aye, slept even with the burden of murder upon my soul!      During the former the creature left me no moment alone; and, in the latter, I started, hourly, from dreams of unutterable fear, to find the hot breath of the thing upon my face, and its vast weight—an incarnate Night-Mare that I had no power to shake off—incumbent eternally upon my heart!      But my disease grew upon me—for what disease is like Alcohol!—and at length even Pluto, who was now becoming old, and consequently somewhat peevish—even Pluto began to experience the effects of my ill temper.      I went so far as to regret the loss of the animal, and to look about me, among the vile haunts which I now habitually frequented, for another pet of the same species, and of somewhat similar appearance, with which to supply its place.      It was now the representation of an object that I shudder to name—and for this, above all, I loathed, and dreaded, and would have rid myself of the monster had I dared—it was now, I say, the image of a hideous—of a ghastly thing—of the GALLOWS!—oh, mournful and terrible engine of Horror and of Crime—of Agony and of Death!      When reason returned with the morning—when I had slept off the fumes of the night’s debauch—I experienced a sentiment half of horror, half of remorse, for the crime of which I had been guilty; but it was, at best, a feeble and equivocal feeling, and the soul remained untouched. Hereafter, perhaps, some intellect may be found which will reduce my phantasm to the common-place—some intellect more calm, more logical, and far less excitable than my own, which will perceive, in the circumstances I detail with awe, nothing more than an ordinary succession of very natural causes and effects.      There is something in the unselfish and self-sacrificing love of a brute, which goes directly to the heart of him who has had frequent occasion to test the paltry friendship and gossamer fidelity of mere Man.      I did not, for some weeks, strike, or otherwise violently ill use it; but gradually—very gradually—I came to look upon it with unutterable loathing, and to flee silently from its odious presence, as from the breath of a pestilence.      When it reached the house it domesticated itself at once, and became immediately a great favorite with my wife.      This circumstance, however, only endeared it to my wife, who, as I have already said, possessed, in a high degree, that humanity of feeling which had once been my distinguishing trait, and the source of many of my simplest and purest pleasures.      At such times, although I longed to destroy it with a blow, I was yet withheld from so doing, partly by a memory of my former crime, but chiefly—let me confess it at once—by absolute dread of the beast.      The falling of other walls had compressed the victim of my cruelty into the substance of the freshly-spread plaster; the lime of which, with the flames, and the ammonia from the carcass, had then accomplished the portraiture as I saw it.      The reader will remember that this mark, although large, had been originally very indefinite; but, by slow degrees—degrees nearly imperceptible, and which for a long time my Reason struggled to reject as fanciful—it had, at length, assumed a rigorous distinctness of outline. Pluto had not a white hair upon any portion of his body; but this cat had a large, although indefinite splotch of white, covering nearly the whole region of the breast.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from heapq import nlargest\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Load the CSV file containing Edgar Allan Poe's Short Stories\n",
    "file_path = \"D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Mining\\\\Week 7\\\\archive\\\\preprocessed_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Locate \"The Black Cat\" story\n",
    "story_row = df[df['title'].str.contains('The Black Cat', case=False, na=False)]\n",
    "\n",
    "if not story_row.empty:\n",
    "    story_text = story_row.iloc[0]['text']\n",
    "\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(story_text)\n",
    "\n",
    "    # Calculate word frequencies, excluding stop words and punctuation\n",
    "    word_frequencies = Counter(token.text.lower() for token in doc if not token.is_punct and not token.is_stop)\n",
    "\n",
    "    # Normalize the frequencies\n",
    "    max_frequency = max(word_frequencies.values())\n",
    "    normalized_word_frequencies = {word: freq / max_frequency for word, freq in word_frequencies.items()}\n",
    "\n",
    "    # Score sentences based on word frequencies\n",
    "    sentence_scores = {sent: sum(normalized_word_frequencies.get(word.text.lower(), 0) for word in sent) for sent in doc.sents}\n",
    "\n",
    "    # Obtain summary by selecting the top scoring sentences\n",
    "    summary_length = int(len(sentence_scores) * 0.1)  \n",
    "    summary_sentences = nlargest(summary_length, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join([sent.text for sent in summary_sentences])\n",
    "    print(\"Summary of 'The Black Cat':\\n\", summary)\n",
    "else:\n",
    "    print(\"The story 'The Black Cat' was not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b41be-f393-4a24-90eb-e5ae500e6bc2",
   "metadata": {},
   "source": [
    "#### Notes and Observations:\n",
    "Various challenges were encountered. Initially, an attempt was made to summarize a movie, but this proved unsuccessful due to the screenplay's unique format, which includes dialogue interspersed with directional notes and scene descriptions. It was noted that screenplays do not follow a uniform narrative structure, making it difficult to extract a concise summary that captures the important parts of the story.\r\n",
    "This assignment submission only shows the first attempt to o summarizing a research paper in PDF forma This also proved challenging as research papers have c complex formatting typical of academic papers, including tables, figures, and equations that were erroneously included in the summary. The specialized vocabulary, mathematical notatis , combined with the limitations othe appliedic NLP tools in contextual understanding and segmentation, led to a summary that, while capturing some key elements, lacked the cohesivene.s.\r\n",
    "\r\n",
    "In contrast, the summarization of \"The Black Cat\" from Edgar Allan Poe's stories, sourced from a Kaggle dataset, proved more successful. This can be attributed to the narrative structure of the story, which is more linear and less complex than a screenplay or a research paper. The text from the Kaggle dataset was more amenable to basic NLP processing, allowing for a more coherent and representative summary. The difference in outcomes across these three texts highlights the varying levels of effectiveness of basic NLP tools depending on the nature of the source material, particularly the structure, complexity, and formatting of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e1b1dc-1bef-46f1-82aa-24f61f9a52e9",
   "metadata": {},
   "source": [
    "##### References:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf5491f-7bf4-4620-be96-d22e25107584",
   "metadata": {},
   "source": [
    "Roser, L. (n.d.). E.A. Poe's corpus of short stories. Kaggle. https://www.kaggle.com/datasets/leangab/poe-short-stories-corpuscsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20d77d-f1ec-40e8-8ce3-e61cafec2be4",
   "metadata": {},
   "source": [
    "Sun, X. (2023). Drug repositioning with adaptive graph convolutional networks. Bioinformatics. https://doi.org/10.1093/bioinformatics/btad748"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
